{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainCNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOgqglTEPlzq5UxwTZXepYW"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDodmC6tPd6z"
      },
      "source": [
        "train_path = r'file_name'\n",
        "test_path = r'file_name'\n",
        "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=train_path, target_size=(64,64), class_mode='categorical', batch_size=10,shuffle=True)\n",
        "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=test_path, target_size=(64,64), class_mode='categorical', batch_size=10, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C0SE6ykPozK"
      },
      "source": [
        "imgs, labels = next(train_batches)\n",
        "#Plotting the images...\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 10, figsize=(30,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "plotImages(imgs)\n",
        "print(imgs.shape)\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_PEpNxMPrh0"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(64,64,3)))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64,activation =\"relu\"))\n",
        "model.add(Dense(128,activation =\"relu\"))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(128,activation =\"relu\"))\n",
        "#model.add(Dropout(0.3))\n",
        "model.add(Dense(10,activation =\"softmax\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ls1wfVqUPuta"
      },
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0001)\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
        "model.compile(optimizer=SGD(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0005)\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95xjzMXBPxdK"
      },
      "source": [
        "history2 = model.fit(train_batches, epochs=10, callbacks=[reduce_lr, early_stop],  validation_data = test_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj3cvIODPz4X"
      },
      "source": [
        "# For getting next batch of testing imgs...\n",
        "imgs, labels = next(test_batches) \n",
        "scores = model.evaluate(imgs, labels, verbose=0)\n",
        "print(f'{model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "Once the model is fitted we save the model using model.save()  function.\n",
        "model.save('best_model_dataflair3.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92ACvY84P2Hg"
      },
      "source": [
        "word_dict = {0:'One',1:'Ten',2:'Two',3:'Three',4:'Four',5:'Five',6:'Six',7:'Seven',8:'Eight',9:'Nine'}\n",
        "predictions = model.predict(imgs, verbose=0)\n",
        "print(\"predictions on a small set of test data--\")\n",
        "print(\"\")\n",
        "for ind, i in enumerate(predictions):\n",
        "    print(word_dict[np.argmax(i)], end='   ')\n",
        "plotImages(imgs)\n",
        "print('Actual labels')\n",
        "for i in labels:\n",
        "    print(word_dict[np.argmax(i)], end='   ')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}